{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<!-- Mejorar visualización en proyector -->\n",
    "<style>\n",
    ".rendered_html {font-size: 1.2em; line-height: 150%;}\n",
    "div.prompt {min-width: 0ex; }\n",
    ".container {width:95% !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoundLapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "''' TimeLapse 2019 '''\n",
    "import funcionestimelapse as tl\n",
    "import file\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import soundfile as audio\n",
    "from scipy.io import wavfile\n",
    "print ('Iniciando Sound-Lapse.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soundscape input ",
    "#### Select audios that will make up the audio capsule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filez = file.filebrowser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "#### Entering desired parameters for the creation of the representative sound capsule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_t_inic      = float(input('Comienzo de Sounlapse:[min] ') )  # min. Tiempo en que comienza el timelapse.\n",
    "in_t_segm      = float(input('Duracion de cada muestra:[seg] ') )  # seg. Duración de cada segmento.\n",
    "in_t_delta     = float(input('Intervalo entre muestras:[min] '))  # min. Delta de tiempo entre segmentos.\n",
    "in_t_fade      = float(input('Duracion de entrelazamineto:[seg] '))  # seg. Duración de fades y crossfaders.\n",
    "crossfade_type = int(input('Tipo de entrelazamiento:(1 Lineal,2 Exponencial,3 Logaritmico) '))  # Tipo de Crossfade.\n",
    "cross_out      = tl.get_cross_out(crossfade_type)  # Obtiene el dato de tipo de crossfade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion SoundLapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont          = 0  # Conteo. Para registro de barra de progreso.\n",
    "for filepath in filez:\n",
    "    in_sig                                  = audio.SoundFile(filepath, 'r')  # Lectura de Audio.\n",
    "    samp_freq                               = in_sig.samplerate  # Frecuencia de Muestreo.\n",
    "    len_in_sig                              = len(in_sig)  # Número de muestras de la señal.\n",
    "    # Preprocesado: Transformación de seg/min a muestras.\n",
    "    m_desc, m_fades, m_inic_desc, m_segment = tl.time_to_samples(in_t_inic, in_t_segm, in_t_delta, in_t_fade, samp_freq)\n",
    "    stereo                                  = tl.check_stereo(in_sig)\n",
    "    if stereo==True:\n",
    "        if filepath == filez[0]:\n",
    "            chunk_fadeout = np.zeros(shape=(1, 2))\n",
    "            time_lapse_vector = np.zeros(shape=(1, 2))  # Prealocación de vector de ceros para el timelapse.\n",
    "    else:\n",
    "        if filepath == filez[0]:\n",
    "            chunk_fadeout = np.zeros(shape=(1, ))\n",
    "            time_lapse_vector = np.zeros(shape=(1, ))  # Prealocación de vector de ceros para el timelapse.\n",
    "    fadein_vect, fadeout_vect, cross_out    = tl.get_crossfaders(crossfade_type, m_fades,stereo)  # Vectores de crossfaders.\n",
    "    # Segmentación\n",
    "    n_chunks                                = tl.get_nchunks(len_in_sig, m_inic_desc, m_segment, m_desc)  # Número de segmentos del timelapse\n",
    "    m_rest                                  = len_in_sig  # Muestras restantes del vector de audio original.\n",
    "    time_lapse_vector, chunk_fadeout, cont  = tl.get_timelapse_one_file(in_sig, n_chunks, fadein_vect, fadeout_vect,\n",
    "                                                                       m_inic_desc, m_segment, m_desc, m_fades,\n",
    "                                                                       time_lapse_vector, filez, filepath,\n",
    "                                                                       chunk_fadeout, cont)  # Genera TimeLapse\n",
    "\n",
    "print (\"Ha finalizado la segmentación de audio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportacion \n",
    "#### Se guarda archivo en formato de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stereo==True:\n",
    "    outfile = 'Outputs/SoundLapse_'+str(int(in_t_inic))+'_'+str(int(in_t_segm))+'_'+str(int(in_t_delta))+'_'+str(int(in_t_fade))+'_'+'cross_' + cross_out\n",
    "    f       = audio.SoundFile(outfile+'.wav', 'w',samplerate=samp_freq,channels=2,subtype='PCM_16',endian='BIG',format='WAV')\n",
    "    f.write(time_lapse_vector)\n",
    "    f.close()\n",
    "else:\n",
    "    outfile = 'Outputs/SoundLapse_'+str(int(in_t_inic))+'_'+str(int(in_t_segm))+'_'+str(int(in_t_delta))+'_'+str(int(in_t_fade))+'_'+'cross_' + cross_out\n",
    "    f       = audio.SoundFile(outfile+'.wav', 'w',samplerate=samp_freq,channels=1,subtype='PCM_16',endian='BIG',format='WAV')\n",
    "    f.write(time_lapse_vector)\n",
    "    f.close()\n",
    "print (\"Exportando archivo \" + outfile + \".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estereo a mono\n",
    "#### Para la representacion grafica del Soundlapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stereo ==True:\n",
    "    sample_rate, samples = wavfile.read(outfile+'.wav')\n",
    "    mono_samples         = tl.stereoToMono(samples)\n",
    "    f_mono               = audio.SoundFile(outfile+\"_mono.wav\", 'w',samplerate=samp_freq,channels=1,subtype='PCM_16',endian='BIG',format='WAV')\n",
    "    f_mono.write(mono_samples)\n",
    "    f_mono.close()\n",
    "print ('TimeLapse finalizado.')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
