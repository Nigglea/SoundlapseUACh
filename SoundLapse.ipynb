{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoundLapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO   ] [Logger      ] Record log in /Users/Nigglea/.kivy/logs/kivy_19-11-29_0.txt\n",
      "[INFO   ] [Kivy        ] v2.0.0.dev0, git-Unknown, 20191112\n",
      "[INFO   ] [Kivy        ] Installed at \"/usr/local/lib/python3.7/site-packages/kivy/__init__.py\"\n",
      "[INFO   ] [Python      ] v3.7.5 (default, Nov  1 2019, 02:16:38) \n",
      "[Clang 10.0.0 (clang-1000.11.45.5)]\n",
      "[INFO   ] [Python      ] Interpreter at \"/usr/local/opt/python/bin/python3.7\"\n",
      "[INFO   ] [Factory     ] 184 symbols loaded\n",
      "[INFO   ] [ImageLoaderFFPy] Using ffpyplayer 4.2.0\n",
      "[INFO   ] [Image       ] Providers: img_tex, img_imageio, img_dds, img_sdl2, img_pil, img_ffpyplayer, img_gif \n",
      "[INFO   ] [Text        ] Provider: sdl2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Sound-Lapse.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "''' TimeLapse 2019 '''\n",
    "import Soundlapse.funcionestimelapse as tl\n",
    "from Soundlapse import logspec\n",
    "from Soundlapse import file\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import soundfile as audio\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "print ('Iniciando Sound-Lapse.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingreso de archivo(s) de audio\n",
    "#### Seleccionar audio(s) que compondran la capsula de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filez = file.filebrowser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "#### Ingreso de parametros deseados para la creacion de la muestra representativa de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comienzo de Sounlapse:[min] 10\n",
      "Duracion de cada muestra:[seg] 22\n",
      "Intervalo entre muestras:[min] 60\n",
      "Duracion de entrelazamineto:[seg] 6\n",
      "Tipo de entrelazamiento:(1 Lineal,2 Exponencial,3 Logaritmico) 3\n",
      "Ha escogido fade logarítmico.\n"
     ]
    }
   ],
   "source": [
    "in_t_inic      = float(input('Comienzo de Sounlapse:[min] ') )  # min. Tiempo en que comienza el timelapse.\n",
    "in_t_segm      = float(input('Duracion de cada muestra:[seg] ') )  # seg. Duración de cada segmento.\n",
    "in_t_delta     = float(input('Intervalo entre muestras:[min] '))  # min. Delta de tiempo entre segmentos.\n",
    "in_t_fade      = float(input('Duracion de entrelazamineto:[seg] '))  # seg. Duración de fades y crossfaders.\n",
    "crossfade_type = int(input('Tipo de entrelazamiento:(1 Lineal,2 Exponencial,3 Logaritmico) '))  # Tipo de Crossfade.\n",
    "cross_out      = tl.get_cross_out(crossfade_type)  # Obtiene el dato de tipo de crossfade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion SoundLapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progreso: 99.99999999999999%.  Ha finalizado la segmentación de audio.\n"
     ]
    }
   ],
   "source": [
    "chunk_fadeout = np.zeros(shape=(1, 2))\n",
    "cont          = 0  # Conteo. Para registro de barra de progreso.\n",
    "for filepath in filez:\n",
    "    if filepath == filez[0]:\n",
    "        time_lapse_vector = np.zeros(shape=(1, 2))  # Prealocación de vector de ceros para el timelapse.\n",
    "    in_sig                                  = audio.SoundFile(filepath, 'r')  # Lectura de Audio.\n",
    "    samp_freq                               = in_sig.samplerate  # Frecuencia de Muestreo.\n",
    "    len_in_sig                              = len(in_sig)  # Número de muestras de la señal.\n",
    "    # Preprocesado: Transformación de seg/min a muestras.\n",
    "    m_desc, m_fades, m_inic_desc, m_segment = tl.time_to_samples(in_t_inic, in_t_segm, in_t_delta, in_t_fade, samp_freq)\n",
    "    fadein_vect, fadeout_vect, cross_out    = tl.get_crossfaders(crossfade_type, m_fades)  # Vectores de crossfaders.\n",
    "    # Segmentación\n",
    "    n_chunks                                = tl.get_nchunks(len_in_sig, m_inic_desc, m_segment, m_desc)  # Número de segmentos del timelapse\n",
    "    m_rest                                  = len_in_sig  # Muestras restantes del vector de audio original.\n",
    "    time_lapse_vector, chunk_fadeout, cont  = tl.get_timelapse_one_file(in_sig, n_chunks, fadein_vect, fadeout_vect,\n",
    "                                                                       m_inic_desc, m_segment, m_desc, m_fades,\n",
    "                                                                       time_lapse_vector, filez, filepath,\n",
    "                                                                       chunk_fadeout, cont)  # Genera TimeLapse\n",
    "\n",
    "print (\"Ha finalizado la segmentación de audio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportacion \n",
    "#### Se guarda archivo en formato de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportando archivo Outputs/SoundLapse_10.0_22.0_60.0_6.0_cross_logaritmico.wav\n"
     ]
    }
   ],
   "source": [
    "outfile = 'Outputs/SoundLapse_'+str(in_t_inic)+'_'+str(in_t_segm)+'_'+str(in_t_delta)+'_'+str(in_t_fade)+'_'+'cross_' + cross_out\n",
    "f       = audio.SoundFile(outfile, 'w',samplerate=samp_freq,channels=2,subtype='PCM_16',endian='BIG',format='WAV')\n",
    "f.write(time_lapse_vector)\n",
    "f.close()\n",
    "print (\"Exportando archivo \" + outfile + \".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estereo a mono\n",
    "#### Para la representacion grafica del Soundlapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeLapse finalizado.\n"
     ]
    }
   ],
   "source": [
    "sample_rate, samples = wavfile.read(outfile)\n",
    "mono_samples         = tl.stereoToMono(samples)\n",
    "f_mono               = audio.SoundFile(outfile+\"_mono.wav\", 'w',samplerate=samp_freq,channels=1,subtype='PCM_16',endian='BIG',format='WAV')\n",
    "f_mono.write(mono_samples)\n",
    "f_mono.close()\n",
    "print ('TimeLapse finalizado.')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
