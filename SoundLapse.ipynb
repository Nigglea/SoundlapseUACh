{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoundLapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "''' TimeLapse 2019 '''\n",
    "import Soundlapse.funcionestimelapse as tl\n",
    "from Soundlapse import file\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import soundfile as audio\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "print ('Iniciando Sound-Lapse.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingreso de archivo(s) de audio\n",
    "#### Seleccionar audio(s) que compondran la capsula de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filez = file.filebrowser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "#### Ingreso de parametros deseados para la creacion de la muestra representativa de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_t_inic      = float(input('Comienzo de Sounlapse:[min] ') )  # min. Tiempo en que comienza el timelapse.\n",
    "in_t_segm      = float(input('Duracion de cada muestra:[seg] ') )  # seg. Duración de cada segmento.\n",
    "in_t_delta     = float(input('Intervalo entre muestras:[min] '))  # min. Delta de tiempo entre segmentos.\n",
    "in_t_fade      = float(input('Duracion de entrelazamineto:[seg] '))  # seg. Duración de fades y crossfaders.\n",
    "crossfade_type = int(input('Tipo de entrelazamiento:(1 Lineal,2 Exponencial,3 Logaritmico) '))  # Tipo de Crossfade.\n",
    "cross_out      = tl.get_cross_out(crossfade_type)  # Obtiene el dato de tipo de crossfade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion SoundLapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_fadeout = np.zeros(shape=(1, 2))\n",
    "cont          = 0  # Conteo. Para registro de barra de progreso.\n",
    "for filepath in filez:\n",
    "    if filepath == filez[0]:\n",
    "        time_lapse_vector = np.zeros(shape=(1, 2))  # Prealocación de vector de ceros para el timelapse.\n",
    "    in_sig                                  = audio.SoundFile(filepath, 'r')  # Lectura de Audio.\n",
    "    samp_freq                               = in_sig.samplerate  # Frecuencia de Muestreo.\n",
    "    len_in_sig                              = len(in_sig)  # Número de muestras de la señal.\n",
    "    # Preprocesado: Transformación de seg/min a muestras.\n",
    "    m_desc, m_fades, m_inic_desc, m_segment = tl.time_to_samples(in_t_inic, in_t_segm, in_t_delta, in_t_fade, samp_freq)\n",
    "    fadein_vect, fadeout_vect, cross_out    = tl.get_crossfaders(crossfade_type, m_fades)  # Vectores de crossfaders.\n",
    "    # Segmentación\n",
    "    n_chunks                                = tl.get_nchunks(len_in_sig, m_inic_desc, m_segment, m_desc)  # Número de segmentos del timelapse\n",
    "    m_rest                                  = len_in_sig  # Muestras restantes del vector de audio original.\n",
    "    time_lapse_vector, chunk_fadeout, cont  = tl.get_timelapse_one_file(in_sig, n_chunks, fadein_vect, fadeout_vect,\n",
    "                                                                       m_inic_desc, m_segment, m_desc, m_fades,\n",
    "                                                                       time_lapse_vector, filez, filepath,\n",
    "                                                                       chunk_fadeout, cont)  # Genera TimeLapse\n",
    "\n",
    "print (\"Ha finalizado la segmentación de audio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportacion \n",
    "#### Se guarda archivo en formato de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'Outputs/SoundLapse_'+str(in_t_inic)+'_'+str(in_t_segm)+'_'+str(in_t_delta)+'_'+str(in_t_fade)+'_'+'cross_' + cross_out\n",
    "f       = audio.SoundFile(outfile, 'w',samplerate=samp_freq,channels=2,subtype='PCM_16',endian='BIG',format='WAV')\n",
    "f.write(time_lapse_vector)\n",
    "f.close()\n",
    "print (\"Exportando archivo \" + outfile + \".wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estereo a mono\n",
    "#### Para la representacion grafica del Soundlapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, samples = wavfile.read(outfile)\n",
    "mono_samples         = tl.stereoToMono(samples)\n",
    "f_mono               = audio.SoundFile(outfile+\"_mono.wav\", 'w',samplerate=samp_freq,channels=1,subtype='PCM_16',endian='BIG',format='WAV')\n",
    "f_mono.write(mono_samples)\n",
    "f_mono.close()\n",
    "print ('TimeLapse finalizado.')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
